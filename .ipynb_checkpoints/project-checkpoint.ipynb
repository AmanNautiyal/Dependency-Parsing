{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_sent=\"UD_Hindi-HDTB/hi_hdtb-ud-train.txt\"\n",
    "train_file_stat=\"UD_Hindi-HDTB/hi_hdtb-ud-train.conllu\" \n",
    "test_file_sent=\"UD_Hindi-HDTB/hi_hdtb-ud-test.txt\"\n",
    "test_file_stat=\"UD_Hindi-HDTB/hi_hdtb-ud-test.conllu\" \n",
    "val_file_sent=\"UD_Hindi-HDTB/hi_hdtb-ud-dev.txt\"\n",
    "val_file_stat=\"UD_Hindi-HDTB/hi_hdtb-ud-dev.conllu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_lines(name):\n",
    "    lines=[]\n",
    "    with open(name,'r',encoding = 'utf-8') as f:\n",
    "        lines=f.readlines()\n",
    "    for i in range(0,len(lines)):\n",
    "        lines[i]=lines[i].strip().split('\\t')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats(line):\n",
    "    stats=dict()\n",
    "    stats['id']=int(line[0])\n",
    "    stats['form']=line[1]\n",
    "    stats['lemma']=line[2]\n",
    "    stats['upos']=line[3]\n",
    "    stats['xpos']=line[4]\n",
    "    stats['head']=int(line[6])\n",
    "    stats['deprel']=line[7]\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_exists(head,i,graph):\n",
    "    while i!=head and i!=0:\n",
    "        i=graph[i]\n",
    "    return i==head\n",
    "def projectivity(sentence):\n",
    "    graph=dict()\n",
    "    for word in sentence:\n",
    "        word_id=word['id']\n",
    "        head_id=word['head']\n",
    "        graph[word_id]=head_id\n",
    "    for dependent in graph:\n",
    "        head=graph[dependent]\n",
    "        l= min(head,dependent)+1\n",
    "        r=max(head,dependent)\n",
    "        for i in range(l,r,1):\n",
    "            if not path_exists(head,i,graph):\n",
    "                return False            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_projective(sentences):\n",
    "    filt_sentences=[sentence for sentence in sentences if projectivity(sentence)]\n",
    "    return filt_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "    lines=file_lines(file)\n",
    "    sentences=[]\n",
    "    sentence=[]\n",
    "    for line in lines:\n",
    "        if len(line)<10:\n",
    "            if len(sentence)>0:\n",
    "                #do something with sentence\n",
    "                sentences.append(sentence)\n",
    "                sentence=[]\n",
    "        else:\n",
    "            sentence.append(extract_stats(line))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def parse(sentence):\n",
    "    buffer=list()\n",
    "    stack=[0]\n",
    "    arcs=list()\n",
    "    states=[]\n",
    "    transitions=[]\n",
    "    def perform_action(action,label=''):\n",
    "        nonlocal buffer,stack,arcs,states,transitions\n",
    "        states.append((list(buffer),list(stack),list(arcs)))\n",
    "        transitions.append((action,label))\n",
    "        if action=='shift':\n",
    "            stack.append(buffer.pop())\n",
    "        elif action=='left_arc':\n",
    "            arcs.append((stack[-1],stack[-2],label))\n",
    "            stack.pop(-2)\n",
    "        elif action=='right_arc':\n",
    "            arcs.append((stack[-2],stack[-1],label))\n",
    "            stack.pop()\n",
    "    dependency_graph = defaultdict(lambda: defaultdict())\n",
    "    for word in reversed(sentence): #store in reverse in buffer, so top of buffer is first word\n",
    "        buffer.append(word['id'])\n",
    "        dependency_graph[word['head']][word['id']]=word['deprel']\n",
    "    states=[]\n",
    "    transitions=[]\n",
    "    head_found=dict()\n",
    "    while not (len(stack)==1 and stack[0]==0 and len(buffer)==0):\n",
    "        if len(stack)>=2:\n",
    "            if dependency_graph.get(stack[-1]) is not None and dependency_graph[stack[-1]].get(stack[-2]) is not None:\n",
    "                head_found[stack[-2]]=True\n",
    "                perform_action(action='left_arc',label=dependency_graph[stack[-1]][stack[-2]])\n",
    "            elif dependency_graph.get(stack[-2]) is not None and dependency_graph[stack[-2]].get(stack[-1]) is not None:\n",
    "                if dependency_graph.get(stack[-1]) is not None and any([dependent not in head_found for dependent in dependency_graph[stack[-1]].keys()]):\n",
    "                    perform_action(action='shift')\n",
    "                else:\n",
    "                    head_found[stack[-1]]=True\n",
    "                    perform_action(action='right_arc',label=dependency_graph[stack[-2]][stack[-1]])\n",
    "            else:\n",
    "                perform_action(action='shift')\n",
    "        else:\n",
    "            perform_action(action='shift')\n",
    "    return states,transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_eager(sentence):\n",
    "    buffer=list()\n",
    "    stack=[0]\n",
    "    arcs={}\n",
    "    states=[]\n",
    "    transitions=[]\n",
    "    def perform_action(action,label=''):\n",
    "        nonlocal buffer,stack,arcs,states,transitions\n",
    "        states.append((list(buffer),list(stack),arcs.copy()))\n",
    "        transitions.append((action,label))\n",
    "        if action=='shift':\n",
    "            stack.append(buffer.pop())\n",
    "        elif action=='reduce':\n",
    "            stack.pop()\n",
    "        elif action=='left_arc':\n",
    "            if arcs.get(buffer[-1])==None:\n",
    "                arcs[buffer[-1]]=[(stack.pop(),label)]\n",
    "            else:\n",
    "                arcs[buffer[-1]].append((stack.pop(),label))\n",
    "        elif action=='right_arc':\n",
    "            if arcs.get(stack[-1])==None:\n",
    "                arcs[stack[-1]]=[(buffer[-1],label)]\n",
    "            else:\n",
    "                arcs[stack[-1]].append((buffer[-1],label))\n",
    "            stack.append(buffer.pop())\n",
    "    dependency_graph = defaultdict(lambda: defaultdict())\n",
    "    for word in reversed(sentence): #store in reverse in buffer, so top of buffer is first word\n",
    "        buffer.append(word['id'])\n",
    "        dependency_graph[word['head']][word['id']]=word['deprel']\n",
    "    head_found=dict()\n",
    "    while not len(buffer)==0:\n",
    "        if len(stack)>=1:\n",
    "            if head_found.get(stack[-1])==None and dependency_graph.get(buffer[-1]) is not None and dependency_graph[buffer[-1]].get(stack[-1]) is not None:\n",
    "                head_found[stack[-1]]=True\n",
    "                perform_action(action='left_arc',label=dependency_graph[buffer[-1]][stack[-1]])\n",
    "            elif dependency_graph.get(stack[-1]) is not None and dependency_graph[stack[-1]].get(buffer[-1]) is not None:\n",
    "                head_found[buffer[-1]]=True\n",
    "                perform_action(action='right_arc',label=dependency_graph[stack[-1]][buffer[-1]])\n",
    "            elif head_found.get(stack[-1])!=None:\n",
    "                perform_action(action='reduce')\n",
    "            else:\n",
    "                perform_action(action='shift')\n",
    "        else:\n",
    "            perform_action(action='shift')\n",
    "    return states,transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(feature_array):\n",
    "    feature_names=[]\n",
    "    if 'single_words' in feature_array:\n",
    "        feature_names.extend(['S0_w_p','S0_w','S0_p','N0_w_p','N0_w','N0_p','N1_w_p','N1_w','N1_p','N2_w_p','N2_w','N2_p'])\n",
    "    return feature_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def extract_features(states,transitions,feature_names,sentence):\n",
    "    df=pd.DataFrame(columns=feature_names)\n",
    "    for state in states:\n",
    "        buffer,stack,arcs=state\n",
    "        row={}\n",
    "        for feature_name in feature_names:\n",
    "            feature_tokens=feature_name.split('_')\n",
    "            cur_word=0\n",
    "            val=''\n",
    "            for token in feature_tokens:\n",
    "                \n",
    "                #determining word\n",
    "                if token[0]=='S':\n",
    "                    if int(token[1])<len(stack):\n",
    "                        cur_word=stack[-1-int(token[1])]\n",
    "                        if  cur_word==0:\n",
    "                            row[feature_name]=np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        row[feature_name]=np.nan\n",
    "                        break\n",
    "                elif token[0]=='N':\n",
    "                    if int(token[1])<len(buffer):\n",
    "                        cur_word=buffer[-1-int(token[1])]\n",
    "                        if  cur_word==0:\n",
    "                            row[feature_name]=np.nan\n",
    "                            break\n",
    "                    else:\n",
    "                        row[feature_name]=np.nan\n",
    "                        break\n",
    "                \n",
    "                #determining feature of the word\n",
    "                else:\n",
    "                    for word in sentence:\n",
    "                        if word['id']==cur_word:\n",
    "                            if token=='w':\n",
    "                                if len(val)==0:\n",
    "                                    val=word['form']\n",
    "                                    break\n",
    "                                else:\n",
    "                                    val=val+'_'+word['form']\n",
    "                                    break\n",
    "                            elif token=='p':\n",
    "                                if len(val)==0:\n",
    "                                    val=word['xpos']\n",
    "                                    break\n",
    "                                else:\n",
    "                                    val=val+'_'+word['xpos']\n",
    "                                    break\n",
    "            row[feature_name]=val\n",
    "        df=df.append(row,ignore_index = True)\n",
    "    return df\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences=get_sentences(train_file_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_sentences=filter_non_projective(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filt_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=get_feature_names(['single_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.dataframe(columns=)\n",
    "for sentence in filt_sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "states,transitions=parse_eager(sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=extract_features(states,transitions,feature_names,sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0_w_p</th>\n",
       "      <th>S0_w</th>\n",
       "      <th>S0_p</th>\n",
       "      <th>N0_w_p</th>\n",
       "      <th>N0_w</th>\n",
       "      <th>N0_p</th>\n",
       "      <th>N1_w_p</th>\n",
       "      <th>N1_w</th>\n",
       "      <th>N1_p</th>\n",
       "      <th>N2_w_p</th>\n",
       "      <th>N2_w</th>\n",
       "      <th>N2_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>यह_DEM</td>\n",
       "      <td>यह</td>\n",
       "      <td>DEM</td>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>की_PSP</td>\n",
       "      <td>की</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>यह_DEM</td>\n",
       "      <td>यह</td>\n",
       "      <td>DEM</td>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>की_PSP</td>\n",
       "      <td>की</td>\n",
       "      <td>PSP</td>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>की_PSP</td>\n",
       "      <td>की</td>\n",
       "      <td>PSP</td>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>की_PSP</td>\n",
       "      <td>की</td>\n",
       "      <td>PSP</td>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>की_PSP</td>\n",
       "      <td>की</td>\n",
       "      <td>PSP</td>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>सबसे_INTF</td>\n",
       "      <td>सबसे</td>\n",
       "      <td>INTF</td>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>बड़ी_JJ</td>\n",
       "      <td>बड़ी</td>\n",
       "      <td>JJ</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>एशिया_NNP</td>\n",
       "      <td>एशिया</td>\n",
       "      <td>NNP</td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>में_PSP</td>\n",
       "      <td>में</td>\n",
       "      <td>PSP</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>से_PSP</td>\n",
       "      <td>से</td>\n",
       "      <td>PSP</td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>मस्जिदों_NN</td>\n",
       "      <td>मस्जिदों</td>\n",
       "      <td>NN</td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>है_VM</td>\n",
       "      <td>है</td>\n",
       "      <td>VM</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>एक_QC</td>\n",
       "      <td>एक</td>\n",
       "      <td>QC</td>\n",
       "      <td>।_SYM</td>\n",
       "      <td>।</td>\n",
       "      <td>SYM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         S0_w_p      S0_w  S0_p       N0_w_p      N0_w  N0_p       N1_w_p  \\\n",
       "0                                     यह_DEM        यह   DEM    एशिया_NNP   \n",
       "1        यह_DEM        यह   DEM    एशिया_NNP     एशिया   NNP       की_PSP   \n",
       "2                                  एशिया_NNP     एशिया   NNP       की_PSP   \n",
       "3     एशिया_NNP     एशिया   NNP       की_PSP        की   PSP    सबसे_INTF   \n",
       "4        की_PSP        की   PSP    सबसे_INTF      सबसे  INTF      बड़ी_JJ   \n",
       "5     एशिया_NNP     एशिया   NNP    सबसे_INTF      सबसे  INTF      बड़ी_JJ   \n",
       "6     सबसे_INTF      सबसे  INTF      बड़ी_JJ      बड़ी    JJ  मस्जिदों_NN   \n",
       "7     एशिया_NNP     एशिया   NNP      बड़ी_JJ      बड़ी    JJ  मस्जिदों_NN   \n",
       "8       बड़ी_JJ      बड़ी    JJ  मस्जिदों_NN  मस्जिदों    NN      में_PSP   \n",
       "9     एशिया_NNP     एशिया   NNP  मस्जिदों_NN  मस्जिदों    NN      में_PSP   \n",
       "10                               मस्जिदों_NN  मस्जिदों    NN      में_PSP   \n",
       "11  मस्जिदों_NN  मस्जिदों    NN      में_PSP       में   PSP       से_PSP   \n",
       "12      में_PSP       में   PSP       से_PSP        से   PSP        एक_QC   \n",
       "13  मस्जिदों_NN  मस्जिदों    NN       से_PSP        से   PSP        एक_QC   \n",
       "14       से_PSP        से   PSP        एक_QC        एक    QC        है_VM   \n",
       "15  मस्जिदों_NN  मस्जिदों    NN        एक_QC        एक    QC        है_VM   \n",
       "16                                     एक_QC        एक    QC        है_VM   \n",
       "17        एक_QC        एक    QC        है_VM        है    VM        ।_SYM   \n",
       "18        है_VM        है    VM        ।_SYM         ।   SYM                \n",
       "19        एक_QC        एक    QC        ।_SYM         ।   SYM                \n",
       "\n",
       "        N1_w  N1_p       N2_w_p      N2_w  N2_p  \n",
       "0      एशिया   NNP       की_PSP        की   PSP  \n",
       "1         की   PSP    सबसे_INTF      सबसे  INTF  \n",
       "2         की   PSP    सबसे_INTF      सबसे  INTF  \n",
       "3       सबसे  INTF      बड़ी_JJ      बड़ी    JJ  \n",
       "4       बड़ी    JJ  मस्जिदों_NN  मस्जिदों    NN  \n",
       "5       बड़ी    JJ  मस्जिदों_NN  मस्जिदों    NN  \n",
       "6   मस्जिदों    NN      में_PSP       में   PSP  \n",
       "7   मस्जिदों    NN      में_PSP       में   PSP  \n",
       "8        में   PSP       से_PSP        से   PSP  \n",
       "9        में   PSP       से_PSP        से   PSP  \n",
       "10       में   PSP       से_PSP        से   PSP  \n",
       "11        से   PSP        एक_QC        एक    QC  \n",
       "12        एक    QC        है_VM        है    VM  \n",
       "13        एक    QC        है_VM        है    VM  \n",
       "14        है    VM        ।_SYM         ।   SYM  \n",
       "15        है    VM        ।_SYM         ।   SYM  \n",
       "16        है    VM        ।_SYM         ।   SYM  \n",
       "17         ।   SYM                               \n",
       "18                                               \n",
       "19                                               "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer,stack,arcs=states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
      "stack:\t [0]\n",
      "arcs:\t {}\n",
      "transition:\t ('shift', '')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
      "stack:\t [0, 1]\n",
      "arcs:\t {}\n",
      "transition:\t ('left_arc', 'det')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
      "stack:\t [0]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')]}\n",
      "transition:\t ('shift', '')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4, 3]\n",
      "stack:\t [0, 2]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')]}\n",
      "transition:\t ('right_arc', 'case')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4]\n",
      "stack:\t [0, 2, 3]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')]}\n",
      "transition:\t ('reduce', '')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5, 4]\n",
      "stack:\t [0, 2]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')]}\n",
      "transition:\t ('shift', '')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5]\n",
      "stack:\t [0, 2, 4]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')]}\n",
      "transition:\t ('left_arc', 'advmod')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6, 5]\n",
      "stack:\t [0, 2]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')]}\n",
      "transition:\t ('shift', '')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6]\n",
      "stack:\t [0, 2, 5]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')]}\n",
      "transition:\t ('left_arc', 'amod')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6]\n",
      "stack:\t [0, 2]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('left_arc', 'nmod')\n",
      "buffer:\t [11, 10, 9, 8, 7, 6]\n",
      "stack:\t [0]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('shift', '')\n",
      "buffer:\t [11, 10, 9, 8, 7]\n",
      "stack:\t [0, 6]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('right_arc', 'case')\n",
      "buffer:\t [11, 10, 9, 8]\n",
      "stack:\t [0, 6, 7]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('reduce', '')\n",
      "buffer:\t [11, 10, 9, 8]\n",
      "stack:\t [0, 6]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('right_arc', 'case')\n",
      "buffer:\t [11, 10, 9]\n",
      "stack:\t [0, 6, 8]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('reduce', '')\n",
      "buffer:\t [11, 10, 9]\n",
      "stack:\t [0, 6]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')]}\n",
      "transition:\t ('left_arc', 'nmod')\n",
      "buffer:\t [11, 10, 9]\n",
      "stack:\t [0]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')], 9: [(6, 'nmod'), (10, 'cop'), (11, 'punct')]}\n",
      "transition:\t ('right_arc', 'root')\n",
      "buffer:\t [11, 10]\n",
      "stack:\t [0, 9]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')], 9: [(6, 'nmod'), (10, 'cop'), (11, 'punct')], 0: [(9, 'root')]}\n",
      "transition:\t ('right_arc', 'cop')\n",
      "buffer:\t [11]\n",
      "stack:\t [0, 9, 10]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')], 9: [(6, 'nmod'), (10, 'cop'), (11, 'punct')], 0: [(9, 'root')]}\n",
      "transition:\t ('reduce', '')\n",
      "buffer:\t [11]\n",
      "stack:\t [0, 9]\n",
      "arcs:\t {2: [(1, 'det'), (3, 'case')], 5: [(4, 'advmod')], 6: [(5, 'amod'), (2, 'nmod'), (7, 'case'), (8, 'case')], 9: [(6, 'nmod'), (10, 'cop'), (11, 'punct')], 0: [(9, 'root')]}\n",
      "transition:\t ('right_arc', 'punct')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(states)):\n",
    "    print('buffer:\\t',states[i][0])\n",
    "    print('stack:\\t',states[i][1])\n",
    "    print('arcs:\\t',states[i][2])\n",
    "    print('transition:\\t',transitions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'form': 'यह',\n",
       "  'lemma': 'यह',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DEM',\n",
       "  'head': 2,\n",
       "  'deprel': 'det'},\n",
       " {'id': 2,\n",
       "  'form': 'एशिया',\n",
       "  'lemma': 'एशिया',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'head': 6,\n",
       "  'deprel': 'nmod'},\n",
       " {'id': 3,\n",
       "  'form': 'की',\n",
       "  'lemma': 'का',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'PSP',\n",
       "  'head': 2,\n",
       "  'deprel': 'case'},\n",
       " {'id': 4,\n",
       "  'form': 'सबसे',\n",
       "  'lemma': 'सबसे',\n",
       "  'upos': 'ADV',\n",
       "  'xpos': 'INTF',\n",
       "  'head': 5,\n",
       "  'deprel': 'advmod'},\n",
       " {'id': 5,\n",
       "  'form': 'बड़ी',\n",
       "  'lemma': 'बड़ा',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'head': 6,\n",
       "  'deprel': 'amod'},\n",
       " {'id': 6,\n",
       "  'form': 'मस्जिदों',\n",
       "  'lemma': 'मस्जिद',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NN',\n",
       "  'head': 9,\n",
       "  'deprel': 'nmod'},\n",
       " {'id': 7,\n",
       "  'form': 'में',\n",
       "  'lemma': 'में',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'PSP',\n",
       "  'head': 6,\n",
       "  'deprel': 'case'},\n",
       " {'id': 8,\n",
       "  'form': 'से',\n",
       "  'lemma': 'से',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'PSP',\n",
       "  'head': 6,\n",
       "  'deprel': 'case'},\n",
       " {'id': 9,\n",
       "  'form': 'एक',\n",
       "  'lemma': 'एक',\n",
       "  'upos': 'NUM',\n",
       "  'xpos': 'QC',\n",
       "  'head': 0,\n",
       "  'deprel': 'root'},\n",
       " {'id': 10,\n",
       "  'form': 'है',\n",
       "  'lemma': 'है',\n",
       "  'upos': 'AUX',\n",
       "  'xpos': 'VM',\n",
       "  'head': 9,\n",
       "  'deprel': 'cop'},\n",
       " {'id': 11,\n",
       "  'form': '।',\n",
       "  'lemma': '।',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': 'SYM',\n",
       "  'head': 9,\n",
       "  'deprel': 'punct'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
